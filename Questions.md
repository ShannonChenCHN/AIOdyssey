# Questions
> 拿着一本书或者一个教程从头看到尾，效率比较低，需要有的放矢，带着目标去学，边学学用，跟《如何阅读一本书》里面的主题阅读法有点像。

TODOs:
- P0 LLM 的原理，build from scrach，指令遵循弱具体是什么？原理是什么？
- P0 Fine-tune
   - 如何准备数据集（一定程度上也需要依赖上面那条）
- P1 动手多写写 AI Agents，多看看相关的项目 技术分享准备 
   - https://www.youtube.com/watch?v=ZZ2QUCePgYw&t=90s&ab_channel=GoogleCloudTech
- P2 RAG 的使用、实现原理，动手多写写 build from scratch



问题：
1. 大家都是怎么做 fine-tuning 的？如何准备数据集？比例怎么控制？需要提供上下文背景吗？超参数怎么调？怎么看 loss 曲线这些指标？怎么迭代优化？
2. 大家是怎么做 LLM Twin 的？
3. LLM 的原理是什么？为什么有些模型会出现“指令遵循弱”的问题？
4. 怎么解决延时问题？
5. 开源模型和小模型怎么用？怎么训练一个专门的意图识别模型呢？
6. 如何从 0 写一个 AI Agent(LLM-based application)？
